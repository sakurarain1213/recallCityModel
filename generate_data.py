"""
ç¦»çº¿æ•°æ®ç”Ÿæˆè„šæœ¬ - è§£è€¦æ•°æ®å¤„ç†ä¸æ¨¡å‹è®­ç»ƒ
è¿è¡Œä¸€æ¬¡ï¼Œç”Ÿæˆæ‰€æœ‰å¹´ä»½çš„ Parquet æ–‡ä»¶
"""
import pandas as pd
import gc
from pathlib import Path
from src.config import Config
from src.city_data import CityDataLoader
from src.data_loader import load_raw_data_fast
from src.feature_pipeline import FeaturePipeline


def generate_all_data(start_year, end_year):
    """
    ç”Ÿæˆæ‰€æœ‰å¹´ä»½çš„è®­ç»ƒæ•°æ®å¹¶ä¿å­˜ä¸º Parquet

    Args:
        start_year: èµ·å§‹å¹´ä»½
        end_year: ç»“æŸå¹´ä»½
    """
    print(f"ğŸš€ å¼€å§‹ç¦»çº¿ç”Ÿæˆè®­ç»ƒæ•°æ® ({start_year}-{end_year})...")
    print(f"ğŸ“‚ ç›®æ ‡ç›®å½•: {Config.PROCESSED_DIR}")

    # åˆå§‹åŒ–
    loader = CityDataLoader(Config.DATA_DIR).load_all()
    pipeline = FeaturePipeline(loader, data_dir=Config.PROCESSED_DIR)
    hard_candidates = loader.get_city_ids()

    for year in range(start_year, end_year + 1):
        out_file = Path(Config.PROCESSED_DIR) / f"train_{year}.parquet"
        if out_file.exists():
            print(f"âœ… Year {year} å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
            continue

        print(f"\nğŸ“… Processing Year {year}...")

        # 1. åŠ è½½å¹¶é‡‡æ · (1:4 æ¯”ä¾‹)
        df = load_raw_data_fast(
            Config.DB_PATH,
            year,
            hard_candidates,
            Config.TOTAL_SAMPLES_PER_QUERY
        )
        if df.empty:
            print(f"âš ï¸  Year {year} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
            continue

        print(f"  âœ… é‡‡æ ·å®Œæˆ: {len(df):,} rows")

        # 2. ç‰¹å¾å·¥ç¨‹ (Pipeline ä¼šè‡ªåŠ¨è®¡ç®—åŒçœã€è·ç¦»ã€å†å²ç‰¹å¾)
        # ä½¿ç”¨ mode='eval' ç¡®ä¿ç”Ÿæˆå…¨é‡ç‰¹å¾ (ä¸Dropout)ï¼Œä¿æŒç¡®å®šæ€§
        df = pipeline.transform(df, year, mode='eval', verbose=False)
        print(f"  âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {len(df.columns)} cols")

        # 3. ç˜¦èº« (åˆ é™¤å­—ç¬¦ä¸²åˆ—ï¼Œåªç•™æ•°å€¼)
        cols_to_drop = ['Type_ID', 'Type_ID_orig', 'From_City_orig']
        df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')

        # 4. å¼ºåˆ¶ç±»å‹è½¬æ¢ (Float64 -> Float32)
        for col in df.columns:
            if df[col].dtype == 'float64':
                df[col] = df[col].astype('float32')
            if df[col].dtype == 'int64':
                df[col] = df[col].astype('int32')

        # 5. ä¿å­˜
        df.to_parquet(out_file, index=False, compression='zstd')
        print(f"ğŸ’¾ Saved {len(df):,} rows x {len(df.columns)} cols to {out_file.name}")

        # å†…å­˜æ¸…ç†
        del df
        gc.collect()

    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆ! æ•°æ®ä¿å­˜åœ¨: {Config.PROCESSED_DIR}")


if __name__ == "__main__":
    # æ ¹æ®ä½ çš„éœ€æ±‚ï¼Œç”Ÿæˆåˆ° 2018 (å› ä¸º 2020 æ˜¯æœ€åçš„æ•°æ®)
    generate_all_data(2001, 2018)
