"""
evaluate.py
æé€Ÿè¯„ä¼°è„šæœ¬ - å¤ç”¨è®­ç»ƒç¼“å­˜ï¼Œæ— éœ€é¢å¤–ç”Ÿæˆæ­¥éª¤
"""
# uv run evaluate.py --year 2010    è¿è¡Œè¯„ä¼°ï¼ˆä¾‹å¦‚è¯„ä¼° 2010 å¹´ï¼‰
# uv run evaluate.py --year 2010 --predict è¿è¡Œè¯„ä¼°å¹¶æ¼”ç¤ºå•æ¬¡æ¨ç†
import gc
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import lightgbm as lgb
import matplotlib.pyplot as plt

# å¯¼å…¥ src æ¨¡å—
from src.config import Config
from src.city_data import CityDataLoader
from src.data_loader_v2 import load_raw_data_fast
from src.feature_eng import parse_type_id
from src.historical_features import add_historical_features

# ==============================================================================
# å…¨å±€èµ„æºç®¡ç†
# ==============================================================================
class EvalContext:
    def __init__(self):
        self.model = None
        self.global_features = None
        self.city_ids = None
        self.feature_cols = None

    def load_resources(self, model_path):
        print("æ­£åœ¨åŠ è½½è¯„ä¼°èµ„æº...")
        
        # 1. åŠ è½½æ¨¡å‹
        try:
            self.model = lgb.Booster(model_file=str(model_path))
            self.feature_cols = self.model.feature_name()
            print(f"âœ“ æ¨¡å‹å·²åŠ è½½ï¼Œç‰¹å¾æ•°é‡: {len(self.feature_cols)}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

        # 2. åŠ è½½å…¨å±€ç‰¹å¾è¡¨ (ä¸è®­ç»ƒæ—¶ä¸€è‡´)
        global_feat_path = Path(Config.OUTPUT_DIR) / 'global_city_features.parquet'
        if not global_feat_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°å…¨å±€ç‰¹å¾è¡¨: {global_feat_path}\nè¯·å…ˆè¿è¡Œ: python src/precompute_static_features.py")
        
        # è¯»å–å¹¶ä¼˜åŒ–å†…å­˜
        self.global_features = pd.read_parquet(global_feat_path)
        self.global_features['From_City'] = self.global_features['From_City'].astype('int16')
        self.global_features['To_City'] = self.global_features['To_City'].astype('int16')
        
        # è·å–æ‰€æœ‰ç›®æ ‡åŸå¸‚ID (ç”¨äºæ„é€ å€™é€‰é›†)
        self.city_ids = self.global_features['To_City'].unique().astype('int16')
        print(f"âœ“ å…¨å±€ç‰¹å¾è¡¨å·²åŠ è½½: {len(self.global_features):,} è¡Œ (æ¶µç›– {len(self.city_ids)} ä¸ªåŸå¸‚)")

# ==============================================================================
# è¯„ä¼°æ ¸å¿ƒé€»è¾‘
# ==============================================================================
def evaluate_year(year, ctx, sample_size=None, cache_dir='output/cache'):
    """
    å¯¹æŒ‡å®šå¹´ä»½è¿›è¡Œå…¨é‡å¬å›è¯„ä¼°
    """
    print(f"\n{'='*40}")
    print(f"å¼€å§‹è¯„ä¼°å¹´ä»½: {year}")
    print(f"{'='*40}")
    
    # 1. è·å– Ground Truth (çœŸå®æµå‘)
    # ä½¿ç”¨ load_raw_data_fast è·å–åŸå§‹æ­£æ ·æœ¬
    # neg_sample_rate è®¾ä¸º 1 å³å¯ï¼Œå› ä¸ºæˆ‘ä»¬åªç­›é€‰æ­£æ ·æœ¬
    print("Step 1: åŠ è½½æµ‹è¯•é›† Ground Truth...")
    df_raw = load_raw_data_fast(Config.DB_PATH, year, hard_candidates=[], neg_sample_rate=1)
    
    if df_raw.empty:
        print("âŒ è¯¥å¹´ä»½æ— æ•°æ®")
        return None

    # ç­›é€‰æ­£æ ·æœ¬ (Label > 0 è¡¨ç¤ºå®ƒæ˜¯çœŸå®å­˜åœ¨çš„æµå‘ï¼ŒåŒ…æ‹¬ Rank 1-20)
    df_pos = df_raw[df_raw['Label'] > 0].copy()
    
    # æå–å”¯ä¸€çš„ Queries (Year, Type, From)
    queries = df_pos[['Year', 'Type_ID', 'From_City']].drop_duplicates().reset_index(drop=True)
    
    # é‡‡æ · (å¦‚æœé…ç½®äº†)
    if sample_size and len(queries) > sample_size:
        print(f"âš ï¸ è¿›è¡Œé‡‡æ ·è¯„ä¼°: {sample_size}/{len(queries)}")
        queries = queries.sample(n=sample_size, random_state=42).reset_index(drop=True)
    else:
        print(f"è¯„ä¼°å…¨é‡æŸ¥è¯¢: {len(queries)} ä¸ª")

    # 2. æ„é€ å…¨é‡å€™é€‰é›† (Query x 337 Cities)
    # è¿™æ˜¯ Recall è¯„ä¼°çš„å…³é”®ï¼šå¯¹æ¯ä¸ªå‡ºå‘çš„äººç¾¤ï¼Œæˆ‘ä»¬è¦å¯¹å…¨å›½æ‰€æœ‰åŸå¸‚æ‰“åˆ†
    print(f"Step 2: ç”Ÿæˆå€™é€‰é›† ({len(queries)} Queries x {len(ctx.city_ids)} Cities)...")
    
    # ä½¿ç”¨ Cross Join æ„é€ 
    # æŠ€å·§ï¼šç»™ä¸¤è¾¹éƒ½åŠ ä¸€ä¸ªå¸¸æ•° key è¿›è¡Œ merge
    queries['key'] = 1
    targets = pd.DataFrame({'To_City': ctx.city_ids, 'key': 1})
    
    # ç¬›å¡å°”ç§¯ (å¯èƒ½å¾ˆå¤§ï¼Œæ³¨æ„å†…å­˜)
    candidates = pd.merge(queries, targets, on='key').drop('key', axis=1)
    
    # æ’é™¤ From == To çš„æƒ…å†µ (è‡ªå·±ä¸èƒ½æµå‘è‡ªå·±)
    candidates = candidates[candidates['From_City'] != candidates['To_City']].copy()
    
    print(f"å€™é€‰é›†å¤§å°: {len(candidates):,} è¡Œ")
    
    # 3. ç‰¹å¾å·¥ç¨‹ (å¤ç”¨è®­ç»ƒæ—¶çš„é€»è¾‘)
    print("Step 3: ç‰¹å¾å·¥ç¨‹...")
    
    # A. åˆå¹¶é™æ€ç‰¹å¾ (Year, From, To)
    # æ³¨æ„ï¼šglobal_features åŒ…å« Year åˆ—ï¼Œä¼šè‡ªåŠ¨å¯¹é½
    candidates = candidates.merge(
        ctx.global_features, 
        on=['Year', 'From_City', 'To_City'], 
        how='left'
    )
    
    # B. è§£æ Type_ID (Gender, Age, etc.)
    # å¯¹ unique Type_ID è§£æä¸€æ¬¡ï¼Œç„¶å merge å›å» (æ¯”ç›´æ¥ apply å¿« 100å€)
    unique_types = candidates[['Type_ID']].drop_duplicates()
    unique_types_parsed, _ = parse_type_id(unique_types, verbose=False)
    
    # å¦‚æœ parse_type_id åˆ é™¤äº† Type_ID åˆ—ï¼Œéœ€è¦æ¢å¤ä»¥ä¾¿ merge
    if 'Type_ID' not in unique_types_parsed.columns and 'Type_ID_orig' in unique_types_parsed.columns:
         unique_types_parsed['Type_ID'] = unique_types_parsed['Type_ID_orig'] # æ¢å¤ç”¨äºMerge
    elif 'Type_ID' not in unique_types_parsed.columns:
         # å…œåº•ï¼šå¦‚æœ parse_type_id å®ç°æ”¹å˜
         unique_types_parsed['Type_ID'] = unique_types['Type_ID'].values
         
    # ç§»é™¤ Type_ID_orig é¿å…é‡å¤
    if 'Type_ID_orig' in unique_types_parsed.columns:
        unique_types_parsed = unique_types_parsed.drop(columns=['Type_ID_orig'])
        
    candidates = candidates.merge(unique_types_parsed, on='Type_ID', how='left')

    # C. æ·»åŠ å†å²ç‰¹å¾
    # å…³é”®ï¼šæŒ‡å‘ output/cacheï¼Œå› ä¸º fast_train æŠŠå¤„ç†å¥½çš„å†å²æ•°æ®å­˜åœ¨é‚£é‡Œ
    # training_mode=False (ä¸è¿›è¡Œ Dropoutï¼Œä½¿ç”¨å…¨éƒ¨å†å²ä¿¡æ¯)
    candidates = add_historical_features(
        candidates, 
        year, 
        data_dir=Path(cache_dir), 
        verbose=False, 
        training_mode=False
    )
    
    # D. å‡†å¤‡ç‰¹å¾çŸ©é˜µ X
    # ç¡®ä¿åˆ—é¡ºåºä¸æ¨¡å‹ä¸€è‡´ï¼Œç¼ºå¤±åˆ—å¡« 0
    for col in ctx.feature_cols:
        if col not in candidates.columns:
            candidates[col] = 0
            
    X = candidates[ctx.feature_cols]
    
    # 4. é¢„æµ‹
    print("Step 4: æ¨¡å‹æ‰“åˆ†...")
    candidates['pred_score'] = ctx.model.predict(X)
    
    # 5. è®¡ç®—æŒ‡æ ‡
    print("Step 5: è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    metrics = calculate_metrics(candidates, df_pos)
    
    # æ¸…ç†å†…å­˜
    del candidates, X, df_raw, df_pos
    gc.collect()
    
    return metrics

def calculate_metrics(candidates, ground_truth):
    """
    å‘é‡åŒ–è®¡ç®— Recall@K
    """
    # 1. å‡†å¤‡ Ground Truth é›†åˆ (Year, Type, From, To)
    gt_set = ground_truth[['Year', 'Type_ID', 'From_City', 'To_City']].copy()
    gt_set['is_true'] = 1
    
    # 2. å¯¹æ¯ä¸ª Query å†…éƒ¨æŒ‰åˆ†æ•°æ’åº
    # ä½¿ç”¨ groupby + rank (method='first' ä¿è¯æ’åè¿ç»­)
    # ascending=False è¡¨ç¤ºåˆ†æ•°è¶Šé«˜æ’åè¶Šå‰ (1 æ˜¯ç¬¬ä¸€å)
    candidates['rank'] = candidates.groupby(['Year', 'Type_ID', 'From_City'])['pred_score'] \
                                   .rank(method='first', ascending=False)
    
    # 3. åªä¿ç•™ Top 20 çš„é¢„æµ‹ç»“æœç”¨äºè¯„ä¼° (èŠ‚çœ Join èµ„æº)
    top_preds = candidates[candidates['rank'] <= 20].copy()
    
    # 4. æ ‡è®°å‘½ä¸­æƒ…å†µ
    # Left Join Truth: å¦‚æœé¢„æµ‹çš„ (Query, To) åœ¨ Truth é‡Œï¼Œis_true å°±æ˜¯ 1
    merged = pd.merge(
        top_preds, 
        gt_set, 
        on=['Year', 'Type_ID', 'From_City', 'To_City'], 
        how='left'
    )
    merged['is_hit'] = merged['is_true'].fillna(0)
    
    # 5. èšåˆè®¡ç®—æ¯ä¸ª Query çš„å‘½ä¸­æ•°
    # æŠ€å·§ï¼šç›´æ¥åˆ¤æ–­ rank <= K ä¸” is_hit == 1
    hits = merged.groupby(['Year', 'Type_ID', 'From_City']).apply(
        lambda x: pd.Series({
            'hit_1': ((x['rank'] <= 1) & (x['is_hit'] == 1)).sum(),
            'hit_5': ((x['rank'] <= 5) & (x['is_hit'] == 1)).sum(),
            'hit_10': ((x['rank'] <= 10) & (x['is_hit'] == 1)).sum(),
            'hit_20': ((x['rank'] <= 20) & (x['is_hit'] == 1)).sum()
        })
    ).reset_index()
    
    # 6. è®¡ç®—æ¯ä¸ª Query çš„çœŸå®æ­£æ ·æœ¬æ€»æ•° (åˆ†æ¯)
    gt_counts = gt_set.groupby(['Year', 'Type_ID', 'From_City']).size().reset_index(name='total_true')
    
    # 7. åˆå¹¶åˆ†å­åˆ†æ¯
    eval_df = pd.merge(gt_counts, hits, on=['Year', 'Type_ID', 'From_City'], how='left').fillna(0)
    
    # 8. è®¡ç®— Recall (å¹³å‡å€¼)
    # é˜²æ­¢é™¤ä»¥ 0 (è™½ç„¶ç†è®ºä¸Š total_true >= 1)
    eval_df['total_true'] = eval_df['total_true'].replace(0, 1)
    
    recall_1 = (eval_df['hit_1'] / eval_df['total_true']).mean()
    recall_5 = (eval_df['hit_5'] / eval_df['total_true']).mean()
    recall_10 = (eval_df['hit_10'] / eval_df['total_true']).mean()
    recall_20 = (eval_df['hit_20'] / eval_df['total_true']).mean()
    
    return {
        'recall_1': recall_1,
        'recall_5': recall_5,
        'recall_10': recall_10,
        'recall_20': recall_20,
        'avg_gt_size': eval_df['total_true'].mean(),
        'num_queries': len(eval_df)
    }

# ==============================================================================
# å•æ¬¡æ¨ç†æ¥å£ (ç”¨äºæ¼”ç¤º)
# ==============================================================================
def predict_one(year, type_id, from_city, ctx):
    """
    å•æ¬¡æ¨ç†ï¼šé¢„æµ‹æŸä¸ªäººç¾¤ä»æŸåŸå¸‚å‡ºå‘ï¼Œæœ€å¯èƒ½å»çš„ Top 10 åŸå¸‚
    """
    print(f"\nğŸ”® å•æ¬¡æ¨ç†: {year} | {type_id} | From: {from_city}")
    
    # 1. æ„é€  Query DataFrame
    query = pd.DataFrame([{
        'Year': year,
        'Type_ID': type_id,
        'From_City': int(from_city)
    }])
    
    # 2. æ„é€  Candidates (1 Query x 337 Cities)
    targets = pd.DataFrame({'To_City': ctx.city_ids})
    targets['key'] = 1
    query['key'] = 1
    candidates = pd.merge(query, targets, on='key').drop('key', axis=1)
    candidates = candidates[candidates['From_City'] != candidates['To_City']].copy()
    
    # 3. ç‰¹å¾å·¥ç¨‹ (ç®€åŒ–ç‰ˆ)
    candidates = candidates.merge(ctx.global_features, on=['Year', 'From_City', 'To_City'], how='left')
    
    types, _ = parse_type_id(candidates[['Type_ID']].drop_duplicates(), verbose=False)
    # å…¼å®¹åˆ—å
    if 'Type_ID' not in types.columns and 'Type_ID_orig' in types.columns:
        types['Type_ID'] = types['Type_ID_orig']
        
    candidates = candidates.merge(types, on='Type_ID', how='left')
    
    candidates = add_historical_features(candidates, year, data_dir=Path(Config.OUTPUT_DIR)/'cache', verbose=False)
    
    for col in ctx.feature_cols:
        if col not in candidates.columns:
            candidates[col] = 0
            
    # 4. é¢„æµ‹
    scores = ctx.model.predict(candidates[ctx.feature_cols])
    candidates['score'] = scores
    
    # 5. æ’åºè¾“å‡º
    top10 = candidates.nlargest(10, 'score')[['To_City', 'score']]
    
    # å°è¯•åŠ è½½åŸå¸‚å
    city_map = {}
    try:
        loader = CityDataLoader(Config.DATA_DIR)
        loader.load_city_nodes()
        city_map = loader.get_city_id_to_name()
    except:
        pass
        
    print(f"{'Rank':<5} {'City ID':<10} {'Name':<15} {'Score':<10}")
    print("-" * 45)
    for i, (idx, row) in enumerate(top10.iterrows(), 1):
        city_id = int(row['To_City'])
        name = city_map.get(city_id, "Unknown")
        print(f"{i:<5} {city_id:<10} {name:<15} {row['score']:.4f}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--year', type=int, default=2010, help="è¯„ä¼°å¹´ä»½")
    parser.add_argument('--sample', type=int, default=1000, help="é‡‡æ ·Queryæ•°ï¼Œ0ä¸ºå…¨é‡")
    parser.add_argument('--predict', action='store_true', help="è¿è¡Œå•æ¬¡æ¨ç†æ¼”ç¤º")
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    ctx = EvalContext()
    model_path = Path(Config.OUTPUT_DIR) / 'fast_model.txt'
    
    if not model_path.exists():
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
    else:
        ctx.load_resources(model_path)
        
        # ç¼“å­˜ç›®å½• (fast_train.py çš„è¾“å‡ºç›®å½•)
        CACHE_DIR = Path(Config.OUTPUT_DIR) / 'cache'
        
        # è¿è¡Œè¯„ä¼°
        metrics = evaluate_year(args.year, ctx, sample_size=args.sample if args.sample > 0 else None, cache_dir=CACHE_DIR)
        
        if metrics:
            print("\n" + "="*40)
            print(f"ğŸ“Š è¯„ä¼°ç»“æœæŠ¥å‘Š ({args.year})")
            print("="*40)
            print(f"Queryæ ·æœ¬æ•° : {metrics['num_queries']}")
            print(f"å¹³å‡æ­£æ ·æœ¬æ•° : {metrics['avg_gt_size']:.2f}")
            print("-" * 30)
            print(f"Recall@1   : {metrics['recall_1']:.2%}")
            print(f"Recall@5   : {metrics['recall_5']:.2%}")
            print(f"Recall@10  : {metrics['recall_10']:.2%}")
            print(f"Recall@20  : {metrics['recall_20']:.2%}")
            print("="*40)
            
        # è¿è¡Œæ¼”ç¤º
        if args.predict:
            # æ‰¾ä¸€ä¸ªå­˜åœ¨çš„ Type_ID å’Œ City æ¼”ç¤º
            predict_one(args.year, 'F_30_EduHi_Service_IncML_Unit_5119', 5119, ctx)